<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-108425063-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-108425063-1');
</script>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Weida Liang's Homepage</title>
</head>
<body>
<div id="layout-content">
<p><br /></p>
<h1><b>Weida Liang</b></h1>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:2.5%;width:63%;vertical-align:middle">
        <p>
  I am a first-year Ph.D. student advised by Prof. <a href="https://www.comp.nus.edu.sg/~xiaoxk/">Xiaokui Xiao</a> at the School of Computing (SoC), National University of Singapore (NUS). 
  Previously, I graduated from Tsinghua University with a B.S. degree in Electronic Engineering. Iâ€™ve had the fortune to work with Prof. <a href="http://web.ee.tsinghua.edu.cn/lidongmei/en/index.htm">Dongmei Li</a> at Tsinghua University.
  Afterwards, I joined Center for Speech and Language Technologies (CSLT) as a research intern with Dr. <a href="http://166.111.134.19:7777/lilt/">Lantian Li</a> and Prof. <a href="http://wangd.cslt.org/">Dong Wang</a>.
Then I became an intern in ASR Oteam, Tencent Inc. in Beijing and did research in ASR and Multimodal Learning, organizing <a https://icprmsr.github.io/index.html>ICPR MSR 2022</a> with Dr. <a href="https://scholar.google.com/citations?hl=zh-CN&user=aNKM4-wAAAAJ">Jian Kang</a>, etc.
        </p>
        <p>
  My primary interests lie in various aspects of machine learning (ML), particularly in deep learning as well as its application in differential privacy, etc. My previous interest also focuses on audio processing.
        </p>
          <p><b>Email:</b> lwd17[at]tsinghua.org.com <br />
    <a href="https://github.com/lwd17">Github</a> / <a href="https://scholar.google.com/citations?user=d4DPVXsAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> / 
  <a href="files/Wechat.jpeg">Wechat</a><br />
  </p>
      </td>
      <td style="padding:2.5%;width:35%;max-width:35%">
        <a href="files/weida.jpeg"><img style="width:95%;max-width:95%" alt="profile photo" src="files/weida.jpeg" class="hoverZoomLink"></a>
      </td>
    </tr>
    </tbody></table>




<h2>Research Experience</h2>
  <table width="50%" align="center" border="0" cellpadding="10"><tbody>
    <tr>
      <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle"><img src="figs/NUS.png", width="90%"></td>
      <td width="80%" valign="center" >
        <b>National University of Singapore</b>
        <br /> 2022.8(expected) - 
        <br />
        <br /> <b>Ph.D. Student in Computer Science</b>
        <br /> Advisor: Prof. <a href="https://www.comp.nus.edu.sg/~xiaoxk/">Xiaokui Xiao</a>
      </td>
    </tr>
    <tr>
      <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle;"><img src="figs/tencent.jpg", width="90%"></td>
      <td width="80%" valign="center">
        <b>Tencent</b>
        <br /> 2022.3 - Present
        <br>
        <br> <b>Research Intern</b>
        <br> Advisor: Dr. <a href="https://scholar.google.com/citations?hl=zh-CN&user=aNKM4-wAAAAJ">Jian Kang</a>
      </td>
    </tr>
    <tr>
      <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle"><img src="figs/CSLT.png", width="90%"></td>
      <td width="80%" valign="center">
        <b>Center for Speech and Language Technologies</b>
        <br> 2021.8 - 2022.4
        <br>
        <br> <b>Research Intern</b>
        <br> Advisor: Prof. <a href="http://wangd.cslt.org/">Dong Wang</a>
      </td>
    </tr>
    <tr>
      <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle"><img src="figs/THU.png", width="90%"></td>
      <td width="80%" valign="center">
        <b>Tsinghua University</b>
        <br> 2017.8 - 2021.6
        <br>
        <br> <b>B.S. in Electronic Engineering</b>
        <br> Advisor: Prof. <a href="http://web.ee.tsinghua.edu.cn/lidongmei/en/index.htm">Dongmei Li</a>
      </td>
    </tr>


    </tbody></table>
<h2>Papers</h2>

     <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <img src='figs/icpr_track2.png' width="100%">
      </td> 
          <td style="padding:20px;width:60%;vertical-align:middle">
        ICPR 2022 Challenge on Multi-Modal Subtitle Recognition. ICPR 2022 accepted
        <br />
            Shan Huang, SHEN HUANG, Li Lu, PENGFEI HU, Lijuan Wang, Xiang Wang*, Jian Kang, <p><b>Weida Liang</b>, Lianwen Jin, Yuliang Liu, Yaqiang Wu
        <br />
        <a href="https://icprmsr.github.io/">project page</a>
      </td>
    </tr> 
         <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <img src='figs/paper_map.png' width="100%">
      </td>
           <td style="padding:20px;width:60%;vertical-align:middle">
        Enhanced exemplar autoencoder with cycle consistency loss in any-to-one voice conversion. Interspeech 2022 submitted
        <br />
        <p><b>Weida Liang</b>,
        <a href="http://166.111.134.19:7777/lilt/">Lantian Li</a>,
        <a href="http://wangd.cslt.org/">Dong Wang</a>,
        <a href="http://cslt.riit.tsinghua.edu.cn/mediawiki/index.php/Cslt-member-eng#Wenqiang_Du_.28.E6.9D.9C.E6.96.87.E5.BC.BA.29">Wenqiang Du</a>
        <br />
        <a href="https://arxiv.org/pdf/2204.03847.pdf">pdf</a> /
        <a href="https://gitlab.com/lwd17/enhanced_examplar_ae/-/tree/main/">code</a> / 
        <a href="http://166.111.134.19:7777/liangwd/cycle/">project page</a>
      </td>
    </tr>
       </tbody></table>
<h2>Patent</h2>
A cycle loss based voice conversion device, 2022  
 <h2>Honors &amp; Awards</h2>
  <b>Meritorious Winner</b> in Mathematical Contest in Modeling, 2019<br />
  <b>Bronze Medal</b> in Chinese Mathematical Olympiad, 2017
  <br /><br />
<ul>
    <a href="https://info.flagcounter.com/xFah">
      <img src="https://s11.flagcounter.com/count2/xFah/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" 
           alt="Flag Counter" border="0">
  </a>
</ul>
  
</div>
</body>
</html>
